{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in /usr/local/python/3.10.13/lib/python3.10/site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.10/site-packages (from nltk>=3.8->textblob) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from nltk>=3.8->textblob) (2024.4.16)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.10.13/lib/python3.10/site-packages (from nltk>=3.8->textblob) (4.66.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# adopted from https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart\n",
    "# create a TextBlob\n",
    "\n",
    "%pip install textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "wiki = TextBlob(\"Python is a high-level, general-purpose programming language.\")\n",
    "wiki2 = TextBlob(\"Python은 고급 범용 프로그래밍 언어입니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Python', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('high-level', 'JJ'),\n",
       " ('general-purpose', 'JJ'),\n",
       " ('programming', 'NN'),\n",
       " ('language', 'NN')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# console에서 python -m textblob.download_corpora 먼저 실행\n",
    "# Part-of-speech Tagging¶\n",
    "\n",
    "wiki.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Python은', 'NNP'),\n",
       " ('고급', 'NNP'),\n",
       " ('범용', 'NNP'),\n",
       " ('프로그래밍', 'NNP'),\n",
       " ('언어입니다', 'NNP')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki2.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from konlpy) (1.5.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from konlpy) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.6 in /home/codespace/.local/lib/python3.10/site-packages (from konlpy) (1.26.4)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from JPype1>=0.7.0->konlpy) (24.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "[('Python', 'Alpha'), ('은', 'Noun'), ('고급', 'Noun'), ('범용', 'Noun'), ('프로그래밍', 'Noun'), ('언어', 'Noun'), ('입니다', 'Adjective'), ('.', 'Punctuation')]\n"
     ]
    }
   ],
   "source": [
    "# KoNLPy는 한국어 자연어 처리를 위한 Python 라이브러리\n",
    "# POS 태깅을 포함해 한국어 텍스트 분석에 적합한 여러 도구에 대한 액세스를 제공\n",
    "# KoNLPy는 Mecab, Komoran, Hannanum, Kkma, and Twitter (Okt)등 다양한 한국어 NLP 도구를 지원\n",
    "\n",
    "%pip install konlpy\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "wiki2 = \"Python은 고급 범용 프로그래밍 언어입니다.\"\n",
    "pos_tags = okt.pos(wiki2)\n",
    "print(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['python'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Noun Phrase Extraction¶\n",
    "\n",
    "wiki.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.39166666666666666, subjectivity=0.4357142857142857)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment Analysis¶\n",
    "# Sentiment(polarity, subjectivity)\n",
    "# The polarity score is a float within the range [-1.0, 1.0].\n",
    "# The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective\n",
    "\n",
    "testimonial = TextBlob(\"Textblob is amazingly simple to use. What great fun!\")\n",
    "testimonial.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Beautiful', 'is', 'better', 'than', 'ugly', 'Explicit', 'is', 'better', 'than', 'implicit', 'Simple', 'is', 'better', 'than', 'complex'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "\n",
    "zen = TextBlob(\n",
    "    \"Beautiful is better than ugly. \"\n",
    "    \"Explicit is better than implicit. \"\n",
    "    \"Simple is better than complex.\"\n",
    ")\n",
    "zen.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Beautiful is better than ugly.\"),\n",
       " Sentence(\"Explicit is better than implicit.\"),\n",
       " Sentence(\"Simple is better than complex.\")]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Use', '4', 'spaces', 'per', 'indentation', 'level'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words Inflection and Lemmatization¶\n",
    "\n",
    "sentence = TextBlob(\"Use 4 spaces per indentation level.\")\n",
    "sentence.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'space'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[2].singularize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'levels'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[-1].pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'octopus'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words can be lemmatized by calling the lemmatize method.\n",
    "\n",
    "from textblob import Word\n",
    "w = Word(\"octopi\")\n",
    "w.lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Word(\"went\")\n",
    "w.lemmatize(\"v\")  # Pass in WordNet part of speech (verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('octopus.n.01'), Synset('octopus.n.02')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WordNet Integration¶\n",
    "# You can access the synsets for a Word via the synsets property or the get_synsets method, optionally passing in a part of speech.\n",
    "\n",
    "from textblob import Word\n",
    "from textblob.wordnet import VERB\n",
    "word = Word(\"octopus\")\n",
    "word.synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('chop.v.05'),\n",
       " Synset('hack.v.02'),\n",
       " Synset('hack.v.03'),\n",
       " Synset('hack.v.04'),\n",
       " Synset('hack.v.05'),\n",
       " Synset('hack.v.06'),\n",
       " Synset('hack.v.07'),\n",
       " Synset('hack.v.08')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word(\"hack\").get_synsets(pos=VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tentacles of octopus prepared as food',\n",
       " 'bottom-living cephalopod having a soft oval body with eight long tentacles']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can access the definitions for each synset via the definitions property or the define() method, which can also take an optional part-of-speech argument.\n",
    "\n",
    "Word(\"octopus\").definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one who works hard at boring tasks',\n",
       " 'a politician who belongs to a small clique that controls a political party for private rather than public ends',\n",
       " 'a mediocre and disdained writer',\n",
       " 'a tool (as a hoe or pick or mattock) used for breaking up the surface of the soil',\n",
       " 'a car driven by a person whose job is to take passengers where they want to go in exchange for money',\n",
       " 'an old or over-worked horse',\n",
       " 'a horse kept for hire',\n",
       " 'a saddle horse used for transportation rather than sport etc.',\n",
       " 'cut with a hacking tool',\n",
       " 'be able to manage or manage successfully',\n",
       " 'cut away',\n",
       " 'kick on the arms',\n",
       " 'kick on the shins',\n",
       " 'fix a computer program piecemeal until it works',\n",
       " 'significantly cut up a manuscript',\n",
       " 'cough spasmodically']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word(\"hack\").definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1111111111111111"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob.wordnet import Synset\n",
    "octopus = Synset(\"octopus.n.02\")\n",
    "shrimp = Synset(\"shrimp.n.03\")\n",
    "octopus.path_similarity(shrimp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('dog.n.01'),\n",
       " Synset('frump.n.01'),\n",
       " Synset('dog.n.03'),\n",
       " Synset('cad.n.01'),\n",
       " Synset('frank.n.02'),\n",
       " Synset('pawl.n.01'),\n",
       " Synset('andiron.n.01'),\n",
       " Synset('chase.v.01')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word(\"dog\").get_synsets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07692307692307693"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog = Synset(\"doc.n.01\")\n",
    "octopus.path_similarity(dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['cat', 'dog', 'octopus'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A WordList is a Python list with additional methods.\n",
    "\n",
    "animals = TextBlob(\"cat dog octopus\")\n",
    "animals.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['cats', 'dogs', 'octopodes'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals.words.pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have good spelling!\n"
     ]
    }
   ],
   "source": [
    "# Spelling Correction\n",
    "# Use the correct() method to attempt spelling correction.\n",
    "\n",
    "b = TextBlob(\"I havv goood speling!\")\n",
    "print(b.correct())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fallibility', 1.0)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word objects have a spellcheck() Word.spellcheck() method that returns a list of (word, confidence) tuples with spelling suggestions.\n",
    "\n",
    "from textblob import Word\n",
    "w = Word(\"falibility\")\n",
    "w.spellcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Word and Noun Phrase Frequencies¶\n",
    "# The first is through the word_counts dictionary.\n",
    "\n",
    "\n",
    "monty = TextBlob(\"We are no longer the Knights who say Ni. \"\n",
    "                    \"We are now the Knights who say Ekki ekki ekki PTANG.\")\n",
    "monty.word_counts['ekki']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The second way is to use the count() method.\n",
    "\n",
    "monty.words.count('ekki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can specify whether or not the search should be case-sensitive (default is False).\n",
    "\n",
    "monty.words.count('ekki', case_sensitive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each of these methods can also be used with noun phrases.\n",
    "\n",
    "wiki.noun_phrases.count('python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And/CC/O/O now/RB/B-ADVP/O for/IN/B-PP/B-PNP something/NN/B-NP/I-PNP completely/RB/B-ADJP/O different/JJ/I-ADJP/O ././O/O\n"
     ]
    }
   ],
   "source": [
    "# Parsing\n",
    "# By default, TextBlob uses pattern’s parser\n",
    "\n",
    "b = TextBlob(\"And now for something completely different.\")\n",
    "print(b.parse())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Now', 'is', 'better']),\n",
       " WordList(['is', 'better', 'than']),\n",
       " WordList(['better', 'than', 'never'])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n-grams\n",
    "# The TextBlob.ngrams() method returns a list of tuples of n successive words.\n",
    "\n",
    "blob = TextBlob(\"Now is better than never.\")\n",
    "blob.ngrams(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
